{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import supported libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Train and Test data-sets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = train_data.copy()\n",
    "titanic_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Gather info from the Train data-set\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Gather info from the Train data-set\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View top Train data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View top Test data\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "886          887         0       2                     Montvila, Rev. Juozas   \n",
       "887          888         1       1              Graham, Miss. Margaret Edith   \n",
       "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890         1       1                     Behr, Mr. Karl Howell   \n",
       "890          891         0       3                       Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
       "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
       "887  female  19.0      0      0      112053  30.00   B42        S  \n",
       "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
       "889    male  26.0      0      0      111369  30.00  C148        C  \n",
       "890    male  32.0      0      0      370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Train bottom data\n",
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                          Name     Sex   Age  SibSp  \\\n",
       "413         1305       3            Spector, Mr. Woolf    male   NaN      0   \n",
       "414         1306       1  Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
       "415         1307       3  Saether, Mr. Simon Sivertsen    male  38.5      0   \n",
       "416         1308       3           Ware, Mr. Frederick    male   NaN      0   \n",
       "417         1309       3      Peter, Master. Michael J    male   NaN      1   \n",
       "\n",
       "     Parch              Ticket      Fare Cabin Embarked  \n",
       "413      0           A.5. 3236    8.0500   NaN        S  \n",
       "414      0            PC 17758  108.9000  C105        C  \n",
       "415      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416      0              359309    8.0500   NaN        S  \n",
       "417      1                2668   22.3583   NaN        C  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Test bottom data\n",
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train attributes data types\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test attributes data types\n",
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Summary\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Summary\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train dimension\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dimension\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train attributes name\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test attributes name\n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived         2\n",
       "Pclass           3\n",
       "Name           891\n",
       "Sex              2\n",
       "Age             88\n",
       "SibSp            7\n",
       "Parch            7\n",
       "Ticket         681\n",
       "Fare           248\n",
       "Cabin          147\n",
       "Embarked         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train and Test data-sets : Drop insignificant attributes ###\n",
    "\n",
    "# Finding unique values in Train data\n",
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    418\n",
       "Pclass           3\n",
       "Name           418\n",
       "Sex              2\n",
       "Age             79\n",
       "SibSp            7\n",
       "Parch            8\n",
       "Ticket         363\n",
       "Fare           169\n",
       "Cabin           76\n",
       "Embarked         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding unique values in Test data\n",
    "test_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'PassengerId', 'Name' are having more unique values, so dropping them\n",
    "\n",
    "# Train data-set\n",
    "train_data.drop(['PassengerId', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "# Test data-set\n",
    "test_data.drop(['PassengerId', 'Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-type Before: \n",
      " Survived      int64\n",
      "Pclass        int64\n",
      "Sex          object\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Parch         int64\n",
      "Ticket       object\n",
      "Fare        float64\n",
      "Cabin        object\n",
      "Embarked     object\n",
      "dtype: object\n",
      "-------------------------------------------\n",
      "Data-type After: \n",
      " Survived    category\n",
      "Pclass      category\n",
      "Sex           object\n",
      "Age          float64\n",
      "SibSp       category\n",
      "Parch       category\n",
      "Ticket        object\n",
      "Fare         float64\n",
      "Cabin         object\n",
      "Embarked      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Train data-set : Covert Numerical attributes to Categorical attributes ###\n",
    "\n",
    "# Need to convert these: Survived, Pclass, SibSp, Parch\n",
    "print(\"Data-type Before: \\n\", train_data.dtypes)\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "train_data.loc[:,['Survived', 'Pclass', 'SibSp', 'Parch']] = train_data.loc[:,['Survived', 'Pclass', 'SibSp', 'Parch']].apply(lambda x: x.astype('category'))\n",
    "\n",
    "print(\"Data-type After: \\n\", train_data.dtypes)\n",
    "\n",
    "# or\n",
    "\n",
    "## Convert numeric attributes to categorical at once in train\n",
    "#num_columns = titanic_orig_train.select_dtypes(['int64']).columns\n",
    "#for col in num_columns:\n",
    "#    titanic_orig_train[col] = titanic_orig_train[col].astype('category', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-type Before: \n",
      " Pclass        int64\n",
      "Sex          object\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Parch         int64\n",
      "Ticket       object\n",
      "Fare        float64\n",
      "Cabin        object\n",
      "Embarked     object\n",
      "dtype: object\n",
      "-------------------------------------------\n",
      "Data-type After: \n",
      " Pclass      category\n",
      "Sex           object\n",
      "Age          float64\n",
      "SibSp       category\n",
      "Parch       category\n",
      "Ticket        object\n",
      "Fare         float64\n",
      "Cabin         object\n",
      "Embarked      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Test data-set : Covert Numerical attributes to Categorical attributes ###\n",
    "\n",
    "# Need to convert these: Survived, Pclass, SibSp, Parch\n",
    "print(\"Data-type Before: \\n\", test_data.dtypes)\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "test_data.loc[:,['Pclass', 'SibSp', 'Parch']] = test_data.loc[:,['Pclass', 'SibSp', 'Parch']].apply(lambda x: x.astype('category'))\n",
    "\n",
    "print(\"Data-type After: \\n\", test_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    category\n",
       "Pclass      category\n",
       "Sex         category\n",
       "Age          float64\n",
       "SibSp       category\n",
       "Parch       category\n",
       "Ticket      category\n",
       "Fare         float64\n",
       "Cabin       category\n",
       "Embarked    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train data-set : Convert all \"object\" data-type to \"category\" ###\n",
    "train_data[['Sex', 'Ticket', 'Cabin', 'Embarked']] = train_data[['Sex', 'Ticket', 'Cabin', 'Embarked']].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# View data-types\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      category\n",
       "Sex         category\n",
       "Age          float64\n",
       "SibSp       category\n",
       "Parch       category\n",
       "Ticket      category\n",
       "Fare         float64\n",
       "Cabin       category\n",
       "Embarked    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test data-set : Convert all \"object\" data-type to \"category\" ###\n",
    "test_data[['Sex', 'Ticket', 'Cabin', 'Embarked']] = test_data[['Sex', 'Ticket', 'Cabin', 'Embarked']].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# View data-types\n",
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Ticket        0\n",
      "Fare          0\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "---------------------------\n",
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Ticket        0\n",
      "Fare          0\n",
      "Embarked      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Train data-set : Drop or replace with Mode vales for attributes with more number of NaN values ###\n",
    "\n",
    "# Find the missing values for each attributes\n",
    "print(train_data.isnull().sum(axis=0))\n",
    "\n",
    "print('---------------------------')\n",
    "\n",
    "# Drop the Cabin attribute due to many missing values\n",
    "train_data.drop(['Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Replace with Mode value\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode().iloc[0])\n",
    "\n",
    "# Impute the Age missing values with Mean values\n",
    "#mean_imputer = Imputer()\n",
    "#train_data = pd.DataFrame(mean_imputer.fit_transform(train_data), columns=train_data.columns)\n",
    "\n",
    "# Find the missing values, if any\n",
    "print(train_data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass        0\n",
      "Sex           0\n",
      "Age          86\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Ticket        0\n",
      "Fare          1\n",
      "Cabin       327\n",
      "Embarked      0\n",
      "dtype: int64\n",
      "---------------------------\n",
      "Pclass       0\n",
      "Sex          0\n",
      "Age         86\n",
      "SibSp        0\n",
      "Parch        0\n",
      "Ticket       0\n",
      "Fare         0\n",
      "Embarked     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Test data-set : Drop or replace with Mode vales for attributes with more number of NaN values ###\n",
    "\n",
    "# Find the missing values for each attributes\n",
    "print(test_data.isnull().sum(axis=0))\n",
    "\n",
    "print('---------------------------')\n",
    "\n",
    "# Drop the Cabin attribute due to many missing values\n",
    "test_data.drop(['Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Replace with Mode value\n",
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mode().iloc[0])\n",
    "\n",
    "# Find the missing values, if any\n",
    "print(test_data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORICAL ATTRIBUTES: \n",
      " Index(['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Embarked'], dtype='object')\n",
      "NUMERICAL ATTRIBUTES: \n",
      " Index(['Age', 'Fare'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived    category\n",
       "Pclass      category\n",
       "Sex         category\n",
       "SibSp       category\n",
       "Parch       category\n",
       "Ticket      category\n",
       "Embarked    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train data-set : Separte the Categorical and Numerical data ###\n",
    "\n",
    "# Categorical data Indexes\n",
    "cat_train = train_data.dtypes[train_data.dtypes=='category'].index\n",
    "print('CATEGORICAL ATTRIBUTES: \\n', cat_train)\n",
    "\n",
    "# Numeric data\n",
    "num_train = train_data.columns.difference(cat_train)\n",
    "print('NUMERICAL ATTRIBUTES: \\n', num_train)\n",
    "\n",
    "# Categorical data\n",
    "cat_train_data = pd.DataFrame(train_data[cat_train])\n",
    "cat_train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      category\n",
       "Sex         category\n",
       "SibSp       category\n",
       "Parch       category\n",
       "Ticket      category\n",
       "Embarked    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Target attribute from Categorical data\n",
    "cat_train_data.drop(['Survived'], axis=1, inplace=True)\n",
    "cat_train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age     float64\n",
       "Fare    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric data\n",
    "num_train_data = train_data[num_train]\n",
    "num_train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORICAL ATTRIBUTES: \n",
      " Index(['Pclass', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Embarked'], dtype='object')\n",
      "NUMERICAL ATTRIBUTES: \n",
      " Index(['Age', 'Fare'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass      category\n",
       "Sex         category\n",
       "SibSp       category\n",
       "Parch       category\n",
       "Ticket      category\n",
       "Embarked    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test data-set : Separte the Categorical and Numerical data ###\n",
    "\n",
    "# Categorical data indexes\n",
    "cat_test = test_data.dtypes[test_data.dtypes=='category'].index\n",
    "print('CATEGORICAL ATTRIBUTES: \\n', cat_test)\n",
    "\n",
    "# Numeric data\n",
    "num_test = test_data.columns.difference(cat_test)\n",
    "print('NUMERICAL ATTRIBUTES: \\n', num_test)\n",
    "\n",
    "# Categorical data\n",
    "cat_test_data = pd.DataFrame(test_data[cat_test])\n",
    "cat_test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age     float64\n",
       "Fare    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric data\n",
    "num_test_data = test_data[num_test]\n",
    "num_test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: \n",
      " Age     177\n",
      "Fare      0\n",
      "dtype: int64\n",
      "-------------\n",
      "After: \n",
      " Age     0\n",
      "Fare    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Train data-set : Impute the missing data with MEAN value\n",
    "\n",
    "# Find the missing values\n",
    "print(\"Before: \\n\", num_train_data.isnull().sum(axis=0))\n",
    "\n",
    "print('-------------')\n",
    "\n",
    "# Impute the Age missing values with Mean values\n",
    "mean_imputer = Imputer()\n",
    "num_train_data = pd.DataFrame(mean_imputer.fit_transform(num_train_data), columns=num_train_data.columns)\n",
    "\n",
    "# Find the missing values again\n",
    "print(\"After: \\n\", num_train_data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: \n",
      " Age     86\n",
      "Fare     0\n",
      "dtype: int64\n",
      "-------------\n",
      "After: \n",
      " Age     0\n",
      "Fare    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Test data-set : Impute the missing data with MEAN value\n",
    "\n",
    "# Find the missing values\n",
    "print(\"Before: \\n\", num_test_data.isnull().sum(axis=0))\n",
    "\n",
    "print('-------------')\n",
    "\n",
    "# Impute the Age missing values with Mean values\n",
    "mean_imputer = Imputer()\n",
    "num_test_data = pd.DataFrame(mean_imputer.fit_transform(num_test_data), columns=num_test_data.columns)\n",
    "\n",
    "# Find the missing values again\n",
    "print(\"After: \\n\", num_test_data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Levels: \n",
      " Pclass        3\n",
      "Sex           2\n",
      "SibSp         7\n",
      "Parch         7\n",
      "Ticket      681\n",
      "Embarked      3\n",
      "dtype: int64\n",
      "-------------------\n",
      "After Levels: \n",
      " Pclass      3\n",
      "Sex         2\n",
      "SibSp       7\n",
      "Parch       7\n",
      "Embarked    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Train data-set : Find the number of levels for each attributes\n",
    "\n",
    "print('Before Levels: \\n', cat_train_data.iloc[:,0:6].nunique())\n",
    "\n",
    "#print(cat_train_data[['Ticket']].head())\n",
    "#print('min frequency: ', cat_train_data.groupby('Ticket').size().min())\n",
    "#print('max frequency: ', cat_train_data.groupby('Ticket').size().max())\n",
    "# Group levels according to frequencies\n",
    "\n",
    "print('-------------------')\n",
    "# Drop the Ticket attribute\n",
    "cat_train_data.drop(['Ticket'], axis=1, inplace=True)\n",
    "\n",
    "print('After Levels: \\n', cat_train_data.iloc[:,0:6].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Levels: \n",
      " Pclass      3\n",
      "Sex         2\n",
      "SibSp       7\n",
      "Parch       8\n",
      "Ticket    363\n",
      "dtype: int64\n",
      "----------------\n",
      "After Levels: \n",
      " Pclass      3\n",
      "Sex         2\n",
      "SibSp       7\n",
      "Parch       8\n",
      "Embarked    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Test data-set : Find the number of levels for each attributes\n",
    "\n",
    "print('Before Levels: \\n', cat_test_data.iloc[:,0:5].nunique())\n",
    "\n",
    "print('----------------')\n",
    "# Drop the Ticket attribute\n",
    "cat_test_data.drop(['Ticket'], axis=1, inplace=True)\n",
    "\n",
    "print('After Levels: \\n', cat_test_data.iloc[:,0:5].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age     Fare\n",
      "0  22.0   7.2500\n",
      "1  38.0  71.2833\n",
      "2  26.0   7.9250\n",
      "3  35.0  53.1000\n",
      "4  35.0   8.0500\n",
      "------------------------------\n",
      "        Age      Fare\n",
      "0 -0.592481 -0.502445\n",
      "1  0.638789  0.786845\n",
      "2 -0.284663 -0.488854\n",
      "3  0.407926  0.420730\n",
      "4  0.407926 -0.486337\n"
     ]
    }
   ],
   "source": [
    "### Train data-set - Standardize the Numeric data-set ###\n",
    "\n",
    "print(num_train_data.head())\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "num_train_std = pd.DataFrame(scaler.fit_transform(num_train_data), columns=num_train_data.columns)\n",
    "\n",
    "print(num_train_std.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age     Fare\n",
      "0  34.5   7.8292\n",
      "1  47.0   7.0000\n",
      "2  62.0   9.6875\n",
      "3  27.0   8.6625\n",
      "4  22.0  12.2875\n",
      "------------------------------\n",
      "        Age      Fare\n",
      "0  0.334993 -0.497063\n",
      "1  1.325530 -0.511926\n",
      "2  2.514175 -0.463754\n",
      "3 -0.259330 -0.482127\n",
      "4 -0.655545 -0.417151\n"
     ]
    }
   ],
   "source": [
    "### Test data-set - Standardize the Numeric data-set ###\n",
    "\n",
    "print(num_test_data.head())\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "num_test_std = pd.DataFrame(scaler.fit_transform(num_test_data), columns=num_test_data.columns)\n",
    "\n",
    "print(num_test_std.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:  (5,)\n",
      "Categorical with dummies:  (891, 27)\n",
      "Categorical with only dummies columns:  (22,)\n",
      "Final Categorical with dummies:  (891, 22)\n"
     ]
    }
   ],
   "source": [
    "### Train data-set - Dummify the Categorical attributes ###\n",
    "\n",
    "# Get the Categorical attribute columns\n",
    "cat_train_col = cat_train_data.columns\n",
    "print('Categorical columns: ', cat_train_col.shape)\n",
    "\n",
    "# Convert all Categorical into dummies variables\n",
    "train_cat_dummy = pd.concat([cat_train_data, pd.get_dummies(cat_train_data[:])], axis = 1)\n",
    "print('Categorical with dummies: ', train_cat_dummy.shape)\n",
    "\n",
    "# Get only dummies attributes\n",
    "cat_train_col_dummy = train_cat_dummy.columns.difference(cat_train_col)\n",
    "print('Categorical with only dummies columns: ', cat_train_col_dummy.shape)\n",
    "\n",
    "# Remove orignial Categorical attributes\n",
    "train_cat_dummy = pd.DataFrame(train_cat_dummy[cat_train_col_dummy])\n",
    "print('Final Categorical with dummies: ', train_cat_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:  (5,)\n",
      "Categorical with dummies:  (418, 28)\n",
      "Categorical with only dummies columns:  (23,)\n",
      "Final Categorical with dummies:  (418, 23)\n"
     ]
    }
   ],
   "source": [
    "### Test data-set - Dummify the Categorical attributes ###\n",
    "\n",
    "# Get the Categorical attribute columns\n",
    "cat_test_col = cat_test_data.columns\n",
    "print('Categorical columns: ', cat_test_col.shape)\n",
    "\n",
    "# Convert all Categorical into dummies variables\n",
    "test_cat_dummy = pd.concat([cat_test_data, pd.get_dummies(cat_test_data[:])], axis = 1)\n",
    "print('Categorical with dummies: ', test_cat_dummy.shape)\n",
    "\n",
    "# Get only dummies attributes\n",
    "cat_test_col_dummy = test_cat_dummy.columns.difference(cat_test_col)\n",
    "print('Categorical with only dummies columns: ', cat_test_col_dummy.shape)\n",
    "\n",
    "# Remove orignial Categorical attributes\n",
    "test_cat_dummy = pd.DataFrame(test_cat_dummy[cat_test_col_dummy])\n",
    "print('Final Categorical with dummies: ', test_cat_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data-set - extra columns in Train data than Test data, if any\n",
    "train_cat_dummy.columns.difference(test_cat_dummy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Parch_9'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data-set - extra columns in Train data than Test data, if any\n",
    "test_cat_dummy.columns.difference(train_cat_dummy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Categorical with dummies:  (418, 22)\n"
     ]
    }
   ],
   "source": [
    "test_cat_dummy.drop(['Parch_9'], axis=1, inplace=True)\n",
    "print('Final Categorical with dummies: ', test_cat_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dim:  (891, 22)\n",
      "Train dim:  (891, 2)\n",
      "Test dim:  (418, 22)\n",
      "Test dim:  (418, 2)\n"
     ]
    }
   ],
   "source": [
    "### Merging Numerical and Categorical data-sets ###\n",
    "\n",
    "# Verify the dimension of Train and Test Categorical data\n",
    "print('Train dim: ', train_cat_dummy.shape)\n",
    "print('Train dim: ', num_train_data.shape)\n",
    "\n",
    "# Verify the dimension of Train and Test Numerical data\n",
    "print('Test dim: ', test_cat_dummy.shape)\n",
    "print('Test dim: ', num_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:  (891, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_5</th>\n",
       "      <th>SibSp_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Embarked_C  Embarked_Q  Embarked_S  Parch_0  Parch_1  \\\n",
       "0  22.0   7.2500           0           0           1        1        0   \n",
       "1  38.0  71.2833           1           0           0        1        0   \n",
       "2  26.0   7.9250           0           0           1        1        0   \n",
       "3  35.0  53.1000           0           0           1        1        0   \n",
       "4  35.0   8.0500           0           0           1        1        0   \n",
       "\n",
       "   Parch_2  Parch_3  Parch_4   ...     Pclass_3  Sex_female  Sex_male  \\\n",
       "0        0        0        0   ...            1           0         1   \n",
       "1        0        0        0   ...            0           1         0   \n",
       "2        0        0        0   ...            1           1         0   \n",
       "3        0        0        0   ...            0           1         0   \n",
       "4        0        0        0   ...            1           0         1   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  SibSp_3  SibSp_4  SibSp_5  SibSp_8  \n",
       "0        0        1        0        0        0        0        0  \n",
       "1        0        1        0        0        0        0        0  \n",
       "2        1        0        0        0        0        0        0  \n",
       "3        0        1        0        0        0        0        0  \n",
       "4        1        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data-set - Concatnate Numerical and Categorical data - Without Standardized data\n",
    "train_final = pd.concat([num_train_data, train_cat_dummy], axis = 1)\n",
    "print(\"Train dimension: \", train_final.shape)\n",
    "\n",
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dimension:  (418, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_5</th>\n",
       "      <th>SibSp_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Embarked_C  Embarked_Q  Embarked_S  Parch_0  Parch_1  \\\n",
       "0  34.5   7.8292           0           1           0        1        0   \n",
       "1  47.0   7.0000           0           0           1        1        0   \n",
       "2  62.0   9.6875           0           1           0        1        0   \n",
       "3  27.0   8.6625           0           0           1        1        0   \n",
       "4  22.0  12.2875           0           0           1        0        1   \n",
       "\n",
       "   Parch_2  Parch_3  Parch_4   ...     Pclass_3  Sex_female  Sex_male  \\\n",
       "0        0        0        0   ...            1           0         1   \n",
       "1        0        0        0   ...            1           1         0   \n",
       "2        0        0        0   ...            0           0         1   \n",
       "3        0        0        0   ...            1           0         1   \n",
       "4        0        0        0   ...            1           1         0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  SibSp_3  SibSp_4  SibSp_5  SibSp_8  \n",
       "0        1        0        0        0        0        0        0  \n",
       "1        0        1        0        0        0        0        0  \n",
       "2        1        0        0        0        0        0        0  \n",
       "3        1        0        0        0        0        0        0  \n",
       "4        0        1        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data-set - Concatnate Numerical and Categorical data - Without Standardized data\n",
    "test_final = pd.concat([num_test_data, test_cat_dummy], axis = 1)\n",
    "print(\"Test dimension: \", test_final.shape)\n",
    "\n",
    "test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Train dimension:  (891, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_5</th>\n",
       "      <th>SibSp_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Embarked_C  Embarked_Q  Embarked_S  Parch_0  Parch_1  \\\n",
       "0 -0.592481 -0.502445           0           0           1        1        0   \n",
       "1  0.638789  0.786845           1           0           0        1        0   \n",
       "2 -0.284663 -0.488854           0           0           1        1        0   \n",
       "3  0.407926  0.420730           0           0           1        1        0   \n",
       "4  0.407926 -0.486337           0           0           1        1        0   \n",
       "\n",
       "   Parch_2  Parch_3  Parch_4   ...     Pclass_3  Sex_female  Sex_male  \\\n",
       "0        0        0        0   ...            1           0         1   \n",
       "1        0        0        0   ...            0           1         0   \n",
       "2        0        0        0   ...            1           1         0   \n",
       "3        0        0        0   ...            0           1         0   \n",
       "4        0        0        0   ...            1           0         1   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  SibSp_3  SibSp_4  SibSp_5  SibSp_8  \n",
       "0        0        1        0        0        0        0        0  \n",
       "1        0        1        0        0        0        0        0  \n",
       "2        1        0        0        0        0        0        0  \n",
       "3        0        1        0        0        0        0        0  \n",
       "4        1        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data-set - Concatnate Numerical and Categorical data - Without Standardized data\n",
    "train_final_std = pd.concat([num_train_std, train_cat_dummy], axis = 1)\n",
    "print(\"Standardized Train dimension: \", train_final_std.shape)\n",
    "\n",
    "train_final_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Test dimension:  (418, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_5</th>\n",
       "      <th>SibSp_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.334993</td>\n",
       "      <td>-0.497063</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.325530</td>\n",
       "      <td>-0.511926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.514175</td>\n",
       "      <td>-0.463754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.259330</td>\n",
       "      <td>-0.482127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.655545</td>\n",
       "      <td>-0.417151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Embarked_C  Embarked_Q  Embarked_S  Parch_0  Parch_1  \\\n",
       "0  0.334993 -0.497063           0           1           0        1        0   \n",
       "1  1.325530 -0.511926           0           0           1        1        0   \n",
       "2  2.514175 -0.463754           0           1           0        1        0   \n",
       "3 -0.259330 -0.482127           0           0           1        1        0   \n",
       "4 -0.655545 -0.417151           0           0           1        0        1   \n",
       "\n",
       "   Parch_2  Parch_3  Parch_4   ...     Pclass_3  Sex_female  Sex_male  \\\n",
       "0        0        0        0   ...            1           0         1   \n",
       "1        0        0        0   ...            1           1         0   \n",
       "2        0        0        0   ...            0           0         1   \n",
       "3        0        0        0   ...            1           0         1   \n",
       "4        0        0        0   ...            1           1         0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  SibSp_3  SibSp_4  SibSp_5  SibSp_8  \n",
       "0        1        0        0        0        0        0        0  \n",
       "1        0        1        0        0        0        0        0  \n",
       "2        1        0        0        0        0        0        0  \n",
       "3        1        0        0        0        0        0        0  \n",
       "4        0        1        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data-set - Concatnate Numerical and Categorical data - Without Standardized data\n",
    "test_final_std = pd.concat([num_test_std, test_cat_dummy], axis = 1)\n",
    "print(\"Standardized Test dimension: \", test_final_std.shape)\n",
    "\n",
    "test_final_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data-set into Train and Validation sets  - Without Std ###\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_final, y, test_size=0.3, random_state=56789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 24)\n",
      "(623, 1)\n",
      "------------------\n",
      "(268, 24)\n",
      "(268, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dimension of Train and Test final\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('------------------')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data-set into Train and Validation sets  - With Std ###\n",
    "x_train_std, x_val_std, y_train_std, y_val_std = train_test_split(train_final_std, y, test_size=0.3, \n",
    "                                                                      random_state=56789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 24)\n",
      "(623, 1)\n",
      "------------------\n",
      "(268, 24)\n",
      "(268, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dimension of Train and Test final\n",
    "print(x_train_std.shape)\n",
    "print(y_train_std.shape)\n",
    "\n",
    "print('------------------')\n",
    "print(x_val_std.shape)\n",
    "print(y_val_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Logistic Regression Model\n",
    "\n",
    "model_log = LogisticRegression(C=1.5)\n",
    "model_log.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Train data\n",
    "y_train_prediction = model_log.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Validation data\n",
    "y_val_prediction = model_log.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.8202247191011236\n",
      "Validation Accuracy :  0.7835820895522388\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print(\"Train Accuracy      : \", accuracy_score(y_train, y_train_prediction))\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", accuracy_score(y_val, y_val_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[330  49]\n",
      " [ 63 181]]\n",
      "-------------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[146  24]\n",
      " [ 34  64]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, y_train_prediction))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, y_val_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Test data\n",
    "y_test_prediction = model_log.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Logistic Regression Model - With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "\n",
    "param_grid = {\"C\" : np.arange(1, 3, 0.1), \n",
    "              \"penalty\" : [\"l1\", \"l2\"],         # l1 lasso l2 ridge\n",
    "              \"max_iter\" : [100],  \n",
    "              \"n_jobs\" : [-1]}\n",
    "\n",
    "# Randomized Search Cross Validation returns an Object with best model parameters\n",
    "\n",
    "log_search = RandomizedSearchCV(estimator = log, param_distributions = param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'C': array([1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2,\n",
       "       2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9]), 'penalty': ['l1', 'l2'], 'max_iter': [100], 'n_jobs': [-1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_search.fit(x_train, y_train_std.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.5000000000000013, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.8105939004815409\n",
      "Validation Accuracy :  0.7835820895522388\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', log_search.best_score_)\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", log_search.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[331  48]\n",
      " [ 64 180]]\n",
      "-------------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[146  24]\n",
      " [ 34  64]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, log_search.predict(x_train)))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, log_search.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=7, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_leaf_nodes=7)\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.8378812199036918\n",
      "Validation Accuracy :  0.7910447761194029\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print(\"Train Accuracy      : \", dt.score(x_train, y_train))\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", dt.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[342  37]\n",
      " [ 64 180]]\n",
      "--------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[150  20]\n",
      " [ 36  62]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, dt.predict(x_train)))\n",
    "\n",
    "print('--------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, dt.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Test data\n",
    "y_test_prediction_dt = dt.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Decision Tree\n",
    "\n",
    "#from sklearn.externals.six import StringIO  \n",
    "#from IPython.display import Image  \n",
    "#from sklearn.tree import export_graphviz\n",
    "#import pydotplus\n",
    "\n",
    "#dot_data = StringIO()\n",
    "#export_graphviz(dt, out_file=dot_data, filled=True, rounded=True, special_characters=True)\n",
    "#graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Decision Tree Model - with Randomized Search cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "#            max_features=None, max_leaf_nodes=7, min_impurity_split=1e-07,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "#            splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "dt1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'max_leaf_nodes': np.arange(3, 20, 1),\n",
    "              'min_samples_split': np.arange(0.01, 0.1, 0.001),\n",
    "              'max_depth': np.arange(5, 15, 1),\n",
    "              'min_weight_fraction_leaf': np.arange(0.01, 0.05, 0.001)}\n",
    "\n",
    "# Randomized Search Cross Validation returns an Object with best model parameters\n",
    "\n",
    "rsearch = RandomizedSearchCV(estimator = dt1, param_distributions = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
       "            max_features=None, max_leaf_nodes=5, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=0.09699999999999992,\n",
       "            min_weight_fraction_leaf=0.015999999999999993, presort=False,\n",
       "            random_state=None, splitter='best')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsearch.fit(x_train, y_train_std.iloc[:,0])\n",
    "rsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.8089887640449438\n",
      "Validation Accuracy :  0.7761194029850746\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', rsearch.best_score_)\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", rsearch.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[334  45]\n",
      " [ 60 184]]\n",
      "-------------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[142  28]\n",
      " [ 32  66]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, rsearch.predict(x_train)))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, rsearch.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest - With default values and n_estimators=20 (random)\n",
    "rf = RandomForestClassifier(n_estimators = 80, max_depth=5)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.8587479935794543\n",
      "Validation Accuracy :  0.8134328358208955\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', rf.score(x_train, y_train))\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", rf.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[358  21]\n",
      " [ 67 177]]\n",
      "-------------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[156  14]\n",
      " [ 36  62]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, rf.predict(x_train)))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, rf.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.5, n_estimators=20, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging\n",
    "bg = BaggingClassifier(DecisionTreeClassifier(max_depth=5), max_samples=0.5, max_features=1.0, n_estimators=20)\n",
    "\n",
    "bg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.8667736757624398\n",
      "Validation Accuracy :  0.8097014925373134\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', bg.score(x_train, y_train))\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", bg.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[357  22]\n",
      " [ 61 183]]\n",
      "-------------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[154  16]\n",
      " [ 35  63]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, bg.predict(x_train)))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, bg.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Boosting - Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1, n_estimators=50, random_state=12345)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Boosting - Ada Boost (Default parameters)\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), n_estimators=50, learning_rate=1, algorithm='SAMME', \n",
    "                         random_state=12345)\n",
    "\n",
    "adb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.9261637239165329\n",
      "Validation Accuracy :  0.8097014925373134\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', adb.score(x_train, y_train))\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", adb.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[369  10]\n",
      " [ 36 208]]\n",
      "-------------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[149  21]\n",
      " [ 30  68]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, adb.predict(x_train)))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, adb.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### g) GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=12345, subsample=1.0, verbose=0,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "# min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "# min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, \n",
    "# warm_start=False, presort='auto')\n",
    "\n",
    "gbc = GradientBoostingClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_depth = 4,\n",
    "        n_estimators = 100,\n",
    "        warm_start=True,\n",
    "        random_state=12345\n",
    ")\n",
    "\n",
    "gbc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy      :  0.942215088282504\n",
      "Validation Accuracy :  0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', gbc.score(x_train, y_train))\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", gbc.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Confusion Matrix\n",
      "[[370   9]\n",
      " [ 27 217]]\n",
      "-------------------------------------\n",
      "Validation - Confusion Matrix\n",
      "[[146  24]\n",
      " [ 28  70]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, gbc.predict(x_train)))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, gbc.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Final Submission ########################\n",
    "#Submit the prediction\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test['PassengerId'],\n",
    "        \"Survived\": gbc.predict(test_final)\n",
    "    })\n",
    "submission.to_csv('test_Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <Center> Final Accuracy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final accuracy values from various models applied\n",
    "\n",
    "accuracy_table = {'Logistic_Regression_Train       '   : accuracy_score(y_train, y_train_prediction),\n",
    "                  'Logistic_Regression_Test        '   : accuracy_score(y_val, y_val_prediction),\n",
    "                  \n",
    "                  'Decision_Tree_Train             '   : dt.score(x_train, y_train),\n",
    "                  'Decision_Tree_Test              '   : dt.score(x_val, y_val),\n",
    "                  \n",
    "                  #'Decision_Tree_RandomGrid_Train  '   : rsearch.best_score_,\n",
    "                  #'Decision_Tree_RandomGrid_Test   '   : rsearch.score(x_val, y_val),\n",
    "                  \n",
    "                  'Random_Forest_Train             '   : rf.score(x_train, y_train),\n",
    "                  'Random_Forest_Test              '   : rf.score(x_val, y_val),\n",
    "                  \n",
    "                  'Bagging_Train                   '   : bg.score(x_train, y_train),\n",
    "                  'Bagging_Test                    '   : bg.score(x_val, y_val),\n",
    "                  \n",
    "                  'AdaBoosting_Train               '   : adb.score(x_train, y_train),\n",
    "                  'AdaBoosting_Test                '   : adb.score(x_val, y_val),\n",
    "                  \n",
    "                  'GradientBoostingClassifier_Train'   : gbc.score(x_train, y_train),\n",
    "                  'GradientBoostingClassifier_Test '   : gbc.score(x_val, y_val),\n",
    "                 }\n",
    "\n",
    "# Check the final accuracy table\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### h) KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(x_train_std, y_train_std)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', classifier.score(x_train_std, y_train_std))\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", classifier.score(x_val_std, y_val_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print('Train - Confusion Matrix')\n",
    "print(confusion_matrix(y_train, classifier.predict(x_train_std)))\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print('Validation - Confusion Matrix')\n",
    "print(confusion_matrix(y_val, classifier.predict(x_val_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(classification_report(y_val_std, classifier.predict(x_val_std))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) KNN Model - With RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "#           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "#           weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "knn_neigh = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors' : np.arange(1, 15, 1),\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'n_jobs' : -1,\n",
    "              'leaf_size' : np.arange(25, 75, 5)}\n",
    "\n",
    "# Randomized Search Cross Validation returns an Object with best model parameters\n",
    "\n",
    "knn = RandomizedSearchCV(estimator = knn_neigh, param_distributions = param_grid, n_iter = 10, \n",
    "                             cv=10, scoring='accuracy', random_state=357678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_std.iloc[:,0]\n",
    "knn.fit(x_train_std, y_train_std.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', knn.best_score_)\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", knn.score(x_val_std, y_val_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xg_model = XGBClassifier(booster='gbtree', silent=1, seed=0, base_score=0.5, subsample=0.75, n_jobs=-1)\n",
    "\n",
    "parameters = {'n_estimators':np.arange(50, 100, 3), #83\n",
    "              'max_depth':np.arange(1, 10, 1),#7\n",
    "#             'gamma':np.arange(1, 10, 1), #4\n",
    "#             'max_delta_step': np.arange(1, 10, 1),   #1\n",
    "#             'min_child_weight':np.arange(1, 10, 1), #1 \n",
    "#             'colsample_bytree':np.arange(0.50, 0.75, 0.1),    #0.6,\n",
    "              'learning_rate': np.arange(0.01, 0.1, 0.01)  # 0.040000000000000001\n",
    "            }\n",
    "\n",
    "tune_model =  GridSearchCV(xg_model, parameters, cv=2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_model.fit(x_train, y_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters : \\n', tune_model.best_params_)\n",
    "print('Results : \\n', format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn on the whole data\n",
    "#tune_model.fit(x_val, y_val.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the Train data\n",
    "print('Train Accuracy      : ', tune_model.best_score_)\n",
    "\n",
    "# Accuracy of the Vaildation data\n",
    "print(\"Validation Accuracy : \", tune_model.score(x_val, y_val.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM Model - with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "        \n",
    "gbc1 = xgb.XGBClassifier()\n",
    "\n",
    "param_grid = {'loss' : ['deviance', 'exponential'],\n",
    "             'learning_rate' : [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "             'n_estimators' : [200],\n",
    "             'max_depth' : np.arange(1, 20, 3),\n",
    "#             'subsample' : [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#             'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#             'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#             'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "             'gamma': [0, 0.25, 0.5, 1.0],\n",
    "             'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "             }\n",
    "\n",
    "fit_params = {'eval_metric': 'mlogloss', \n",
    "              'early_stopping_rounds': 50,\n",
    "              'eval_set' : [(x_train, y_train)]\n",
    "             }\n",
    "\n",
    "rs_gbc = RandomizedSearchCV(gbc1, param_distributions=param_grid, n_iter=5, n_jobs=-1, verbose=2, \n",
    "                                cv=10, fit_params=fit_params, random_state = 12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "JoblibXGBoostError",
     "evalue": "JoblibXGBoostError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000224D4736F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000224D4736F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(564, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(564, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (564, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=564, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rs_gbc.fit(x_train, y_train.iloc[:,0])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 30, 10, 8, 17, 622362, tzinfo=tzutc()), 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'session': '42f826f738734673960671e50f29783e', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'42f826f738734673960671e50f29783e']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'rs_gbc.fit(x_train, y_train.iloc[:,0])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 30, 10, 8, 17, 622362, tzinfo=tzutc()), 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'session': '42f826f738734673960671e50f29783e', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'42f826f738734673960671e50f29783e'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rs_gbc.fit(x_train, y_train.iloc[:,0])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 30, 10, 8, 17, 622362, tzinfo=tzutc()), 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'session': '42f826f738734673960671e50f29783e', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='rs_gbc.fit(x_train, y_train.iloc[:,0])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'rs_gbc.fit(x_train, y_train.iloc[:,0])'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('rs_gbc.fit(x_train, y_train.iloc[:,0])',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('rs_gbc.fit(x_train, y_train.iloc[:,0])',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rs_gbc.fit(x_train, y_train.iloc[:,0])', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'rs_gbc.fit(x_train, y_train.iloc[:,0])'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rs_gbc.fit(x_train, y_train.iloc[:,0])', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-108-890652c98351>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 224dbfb9668, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000224DC015660, file \"<ipython-input-108-890652c98351>\", line 1>\n        result = <ExecutionResult object at 224dbfb9668, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000224DC015660, file \"<ipython-input-108-890652c98351>\", line 1>, result=<ExecutionResult object at 224dbfb9668, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000224DC015660, file \"<ipython-input-108-890652c98351>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# Import supported libraries\\nimport numpy as np\\n...from sklearn.metrics import classification_report', '# Read Train and Test data-sets\\ntrain_data = pd....(\"train.csv\")\\ntest_data = pd.read_csv(\"test.csv\")', 'titanic_train = train_data.copy()\\ntitanic_test = test_data.copy()', '# Gather info from the Train data-set\\ntrain_data.info()', '# Gather info from the Train data-set\\ntest_data.info()', '# View top Train data\\ntrain_data.head()', '# View top Test data\\ntest_data.head()', '# View Train bottom data\\ntrain_data.tail()', '# View Test bottom data\\ntest_data.tail()', '# Train attributes data types\\ntrain_data.dtypes', '# Test attributes data types\\ntest_data.dtypes', '# Train Summary\\ntrain_data.describe()', '# Test Summary\\ntest_data.describe()', '# Train dimension\\ntrain_data.shape', '# Test dimension\\ntest_data.shape', '# Train attributes name\\ntrain_data.columns', '# Test attributes name\\ntest_data.columns', '### Train and Test data-sets : Drop insignifican... unique values in Train data\\ntrain_data.nunique()', '# Finding unique values in Test data\\ntest_data.nunique()', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {6:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 7:    PassengerId  Pclass                          ...      1      1  3101298  12.2875   NaN        S  , 8:      PassengerId  Survived  Pclass              ...     0      0      370376   7.75   NaN        Q  , 9:      PassengerId  Pclass                        ... 1                2668   22.3583   NaN        C  , 10: PassengerId      int64\nSurvived         int64\nPc...      object\nEmbarked        object\ndtype: object, 11: PassengerId      int64\nPclass           int64\nNa...      object\nEmbarked        object\ndtype: object, 12:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 13:        PassengerId      Pclass         Age      ...0   76.000000    8.000000    9.000000  512.329200, 14: (891, 12), 15: (418, 11), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# Import supported libraries\\nimport numpy as np\\n...from sklearn.metrics import classification_report', '# Read Train and Test data-sets\\ntrain_data = pd....(\"train.csv\")\\ntest_data = pd.read_csv(\"test.csv\")', 'titanic_train = train_data.copy()\\ntitanic_test = test_data.copy()', '# Gather info from the Train data-set\\ntrain_data.info()', '# Gather info from the Train data-set\\ntest_data.info()', '# View top Train data\\ntrain_data.head()', '# View top Test data\\ntest_data.head()', '# View Train bottom data\\ntrain_data.tail()', '# View Test bottom data\\ntest_data.tail()', '# Train attributes data types\\ntrain_data.dtypes', '# Test attributes data types\\ntest_data.dtypes', '# Train Summary\\ntrain_data.describe()', '# Test Summary\\ntest_data.describe()', '# Train dimension\\ntrain_data.shape', '# Test dimension\\ntest_data.shape', '# Train attributes name\\ntrain_data.columns', '# Test attributes name\\ntest_data.columns', '### Train and Test data-sets : Drop insignifican... unique values in Train data\\ntrain_data.nunique()', '# Finding unique values in Test data\\ntest_data.nunique()', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {6:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 7:    PassengerId  Pclass                          ...      1      1  3101298  12.2875   NaN        S  , 8:      PassengerId  Survived  Pclass              ...     0      0      370376   7.75   NaN        Q  , 9:      PassengerId  Pclass                        ... 1                2668   22.3583   NaN        C  , 10: PassengerId      int64\nSurvived         int64\nPc...      object\nEmbarked        object\ndtype: object, 11: PassengerId      int64\nPclass           int64\nNa...      object\nEmbarked        object\ndtype: object, 12:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 13:        PassengerId      Pclass         Age      ...0   76.000000    8.000000    9.000000  512.329200, 14: (891, 12), 15: (418, 11), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Studies\\INSOFE\\Self Practice\\titanic data-set\\<ipython-input-108-890652c98351> in <module>()\n----> 1 rs_gbc.fit(x_train, y_train.iloc[:,0])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=10, error_score='raise',\n ...turn_train_score='warn', scoring=None, verbose=2), X=           Age      Fare  Embarked_C  Embarked_Q...   0        0        0  \n\n[623 rows x 24 columns], y=787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], groups=None, **fit_params={'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...   0        0        0  \n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>\n        X =            Age      Fare  Embarked_C  Embarked_Q...   0        0        0  \n\n[623 rows x 24 columns]\n        y = 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nXGBoostError                                       Fri Nov 30 15:38:33 2018\nPID: 1432                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], y=787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], scorer={'score': <function _passthrough_scorer>}, train=array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), verbose=2, parameters={'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}, fit_params={'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None, silent=True,\n       subsample=1)>\n        X_train =            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns]\n        y_train = 660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1]\n        fit_params = {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns], y=660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1], sample_weight=None, eval_set=[(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])], eval_metric='mlogloss', early_stopping_rounds=50, verbose=True, xgb_model=None, sample_weight_eval_set=[None], callbacks=None)\n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n    698                               evals_result=evals_result, obj=obj, feval=feval,\n    699                               verbose_eval=verbose, xgb_model=None,\n--> 700                               callbacks=callbacks)\n        callbacks = None\n    701 \n    702         self.objective = xgb_options[\"objective\"]\n    703         if evals_result:\n    704             for val in evals_result.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in train(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, maximize=False, early_stopping_rounds=50, evals_result={}, verbose_eval=True, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>], learning_rates=None)\n    211 \n    212     return _train_internal(params, dtrain,\n    213                            num_boost_round=num_boost_round,\n    214                            evals=evals,\n    215                            obj=obj, feval=feval,\n--> 216                            xgb_model=xgb_model, callbacks=callbacks)\n        xgb_model = None\n        callbacks = [<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>]\n    217 \n    218 \n    219 class CVPack(object):\n    220     \"\"\"\"Auxiliary datastruct to hold one fold of CV.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in _train_internal(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>])\n     79 \n     80         nboost += 1\n     81         evaluation_result_list = []\n     82         # check evaluation result.\n     83         if len(evals) != 0:\n---> 84             bst_eval_set = bst.eval_set(evals, i, feval)\n        bst_eval_set = undefined\n        bst.eval_set = <bound method Booster.eval_set of <xgboost.core.Booster object>>\n        evals = [(<xgboost.core.DMatrix object>, 'validation_0')]\n        i = 0\n        feval = None\n     85             if isinstance(bst_eval_set, STRING_TYPES):\n     86                 msg = bst_eval_set\n     87             else:\n     88                 msg = bst_eval_set.decode()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in eval_set(self=<xgboost.core.Booster object>, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], iteration=0, feval=None)\n   1101         evnames = c_array(ctypes.c_char_p, [c_str(d[1]) for d in evals])\n   1102         msg = ctypes.c_char_p()\n   1103         _check_call(_LIB.XGBoosterEvalOneIter(self.handle, ctypes.c_int(iteration),\n   1104                                               dmats, evnames,\n   1105                                               c_bst_ulong(len(evals)),\n-> 1106                                               ctypes.byref(msg)))\n        msg = c_char_p(None)\n   1107         res = msg.value.decode()\n   1108         if feval is not None:\n   1109             for dmat, evname in evals:\n   1110                 feval_ret = feval(self.predict(dmat), dmat)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _check_call(ret=-1)\n    160     ----------\n    161     ret : int\n    162         return value from API calls\n    163     \"\"\"\n    164     if ret != 0:\n--> 165         raise XGBoostError(_LIB.XGBGetLastError())\n    166 \n    167 \n    168 def ctypes2numpy(cptr, length, dtype):\n    169     \"\"\"Convert a ctypes pointer array to a numpy array.\n\nXGBoostError: b'[15:38:33] C:\\\\Users\\\\Administrator\\\\Desktop\\\\xgboost\\\\src\\\\metric\\\\multiclass_metric.cc:53: Check failed: label_error >= 0 && label_error < static_cast<int>(nclass) MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 1 in label'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 700, in fit\n    callbacks=callbacks)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 216, in train\n    xgb_model=xgb_model, callbacks=callbacks)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 84, in _train_internal\n    bst_eval_set = bst.eval_set(evals, i, feval)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1106, in eval_set\n    ctypes.byref(msg)))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 165, in _check_call\n    raise XGBoostError(_LIB.XGBGetLastError())\nxgboost.core.XGBoostError: b'[15:38:33] C:\\\\Users\\\\Administrator\\\\Desktop\\\\xgboost\\\\src\\\\metric\\\\multiclass_metric.cc:53: Check failed: label_error >= 0 && label_error < static_cast<int>(nclass) MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 1 in label'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nXGBoostError                                       Fri Nov 30 15:38:33 2018\nPID: 1432                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], y=787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], scorer={'score': <function _passthrough_scorer>}, train=array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), verbose=2, parameters={'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}, fit_params={'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None, silent=True,\n       subsample=1)>\n        X_train =            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns]\n        y_train = 660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1]\n        fit_params = {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns], y=660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1], sample_weight=None, eval_set=[(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])], eval_metric='mlogloss', early_stopping_rounds=50, verbose=True, xgb_model=None, sample_weight_eval_set=[None], callbacks=None)\n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n    698                               evals_result=evals_result, obj=obj, feval=feval,\n    699                               verbose_eval=verbose, xgb_model=None,\n--> 700                               callbacks=callbacks)\n        callbacks = None\n    701 \n    702         self.objective = xgb_options[\"objective\"]\n    703         if evals_result:\n    704             for val in evals_result.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in train(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, maximize=False, early_stopping_rounds=50, evals_result={}, verbose_eval=True, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>], learning_rates=None)\n    211 \n    212     return _train_internal(params, dtrain,\n    213                            num_boost_round=num_boost_round,\n    214                            evals=evals,\n    215                            obj=obj, feval=feval,\n--> 216                            xgb_model=xgb_model, callbacks=callbacks)\n        xgb_model = None\n        callbacks = [<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>]\n    217 \n    218 \n    219 class CVPack(object):\n    220     \"\"\"\"Auxiliary datastruct to hold one fold of CV.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in _train_internal(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>])\n     79 \n     80         nboost += 1\n     81         evaluation_result_list = []\n     82         # check evaluation result.\n     83         if len(evals) != 0:\n---> 84             bst_eval_set = bst.eval_set(evals, i, feval)\n        bst_eval_set = undefined\n        bst.eval_set = <bound method Booster.eval_set of <xgboost.core.Booster object>>\n        evals = [(<xgboost.core.DMatrix object>, 'validation_0')]\n        i = 0\n        feval = None\n     85             if isinstance(bst_eval_set, STRING_TYPES):\n     86                 msg = bst_eval_set\n     87             else:\n     88                 msg = bst_eval_set.decode()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in eval_set(self=<xgboost.core.Booster object>, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], iteration=0, feval=None)\n   1101         evnames = c_array(ctypes.c_char_p, [c_str(d[1]) for d in evals])\n   1102         msg = ctypes.c_char_p()\n   1103         _check_call(_LIB.XGBoosterEvalOneIter(self.handle, ctypes.c_int(iteration),\n   1104                                               dmats, evnames,\n   1105                                               c_bst_ulong(len(evals)),\n-> 1106                                               ctypes.byref(msg)))\n        msg = c_char_p(None)\n   1107         res = msg.value.decode()\n   1108         if feval is not None:\n   1109             for dmat, evname in evals:\n   1110                 feval_ret = feval(self.predict(dmat), dmat)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _check_call(ret=-1)\n    160     ----------\n    161     ret : int\n    162         return value from API calls\n    163     \"\"\"\n    164     if ret != 0:\n--> 165         raise XGBoostError(_LIB.XGBGetLastError())\n    166 \n    167 \n    168 def ctypes2numpy(cptr, length, dtype):\n    169     \"\"\"Convert a ctypes pointer array to a numpy array.\n\nXGBoostError: b'[15:38:33] C:\\\\Users\\\\Administrator\\\\Desktop\\\\xgboost\\\\src\\\\metric\\\\multiclass_metric.cc:53: Check failed: label_error >= 0 && label_error < static_cast<int>(nclass) MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 1 in label'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nXGBoostError                                       Fri Nov 30 15:38:33 2018\nPID: 1432                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], y=787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], scorer={'score': <function _passthrough_scorer>}, train=array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), verbose=2, parameters={'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}, fit_params={'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None, silent=True,\n       subsample=1)>\n        X_train =            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns]\n        y_train = 660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1]\n        fit_params = {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns], y=660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1], sample_weight=None, eval_set=[(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])], eval_metric='mlogloss', early_stopping_rounds=50, verbose=True, xgb_model=None, sample_weight_eval_set=[None], callbacks=None)\n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n    698                               evals_result=evals_result, obj=obj, feval=feval,\n    699                               verbose_eval=verbose, xgb_model=None,\n--> 700                               callbacks=callbacks)\n        callbacks = None\n    701 \n    702         self.objective = xgb_options[\"objective\"]\n    703         if evals_result:\n    704             for val in evals_result.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in train(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, maximize=False, early_stopping_rounds=50, evals_result={}, verbose_eval=True, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>], learning_rates=None)\n    211 \n    212     return _train_internal(params, dtrain,\n    213                            num_boost_round=num_boost_round,\n    214                            evals=evals,\n    215                            obj=obj, feval=feval,\n--> 216                            xgb_model=xgb_model, callbacks=callbacks)\n        xgb_model = None\n        callbacks = [<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>]\n    217 \n    218 \n    219 class CVPack(object):\n    220     \"\"\"\"Auxiliary datastruct to hold one fold of CV.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in _train_internal(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>])\n     79 \n     80         nboost += 1\n     81         evaluation_result_list = []\n     82         # check evaluation result.\n     83         if len(evals) != 0:\n---> 84             bst_eval_set = bst.eval_set(evals, i, feval)\n        bst_eval_set = undefined\n        bst.eval_set = <bound method Booster.eval_set of <xgboost.core.Booster object>>\n        evals = [(<xgboost.core.DMatrix object>, 'validation_0')]\n        i = 0\n        feval = None\n     85             if isinstance(bst_eval_set, STRING_TYPES):\n     86                 msg = bst_eval_set\n     87             else:\n     88                 msg = bst_eval_set.decode()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in eval_set(self=<xgboost.core.Booster object>, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], iteration=0, feval=None)\n   1101         evnames = c_array(ctypes.c_char_p, [c_str(d[1]) for d in evals])\n   1102         msg = ctypes.c_char_p()\n   1103         _check_call(_LIB.XGBoosterEvalOneIter(self.handle, ctypes.c_int(iteration),\n   1104                                               dmats, evnames,\n   1105                                               c_bst_ulong(len(evals)),\n-> 1106                                               ctypes.byref(msg)))\n        msg = c_char_p(None)\n   1107         res = msg.value.decode()\n   1108         if feval is not None:\n   1109             for dmat, evname in evals:\n   1110                 feval_ret = feval(self.predict(dmat), dmat)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _check_call(ret=-1)\n    160     ----------\n    161     ret : int\n    162         return value from API calls\n    163     \"\"\"\n    164     if ret != 0:\n--> 165         raise XGBoostError(_LIB.XGBGetLastError())\n    166 \n    167 \n    168 def ctypes2numpy(cptr, length, dtype):\n    169     \"\"\"Convert a ctypes pointer array to a numpy array.\n\nXGBoostError: b'[15:38:33] C:\\\\Users\\\\Administrator\\\\Desktop\\\\xgboost\\\\src\\\\metric\\\\multiclass_metric.cc:53: Check failed: label_error >= 0 && label_error < static_cast<int>(nclass) MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 1 in label'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibXGBoostError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-890652c98351>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrs_gbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibXGBoostError\u001b[0m: JoblibXGBoostError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000224D4736F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000224D4736F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(564, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(564, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (564, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=564, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rs_gbc.fit(x_train, y_train.iloc[:,0])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 30, 10, 8, 17, 622362, tzinfo=tzutc()), 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'session': '42f826f738734673960671e50f29783e', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'42f826f738734673960671e50f29783e']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'rs_gbc.fit(x_train, y_train.iloc[:,0])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 30, 10, 8, 17, 622362, tzinfo=tzutc()), 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'session': '42f826f738734673960671e50f29783e', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'42f826f738734673960671e50f29783e'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rs_gbc.fit(x_train, y_train.iloc[:,0])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 30, 10, 8, 17, 622362, tzinfo=tzutc()), 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'session': '42f826f738734673960671e50f29783e', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f56f48c5a89b418781e67206de85f269', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='rs_gbc.fit(x_train, y_train.iloc[:,0])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'rs_gbc.fit(x_train, y_train.iloc[:,0])'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('rs_gbc.fit(x_train, y_train.iloc[:,0])',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('rs_gbc.fit(x_train, y_train.iloc[:,0])',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rs_gbc.fit(x_train, y_train.iloc[:,0])', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'rs_gbc.fit(x_train, y_train.iloc[:,0])'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rs_gbc.fit(x_train, y_train.iloc[:,0])', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-108-890652c98351>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 224dbfb9668, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000224DC015660, file \"<ipython-input-108-890652c98351>\", line 1>\n        result = <ExecutionResult object at 224dbfb9668, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000224DC015660, file \"<ipython-input-108-890652c98351>\", line 1>, result=<ExecutionResult object at 224dbfb9668, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000224DC015660, file \"<ipython-input-108-890652c98351>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# Import supported libraries\\nimport numpy as np\\n...from sklearn.metrics import classification_report', '# Read Train and Test data-sets\\ntrain_data = pd....(\"train.csv\")\\ntest_data = pd.read_csv(\"test.csv\")', 'titanic_train = train_data.copy()\\ntitanic_test = test_data.copy()', '# Gather info from the Train data-set\\ntrain_data.info()', '# Gather info from the Train data-set\\ntest_data.info()', '# View top Train data\\ntrain_data.head()', '# View top Test data\\ntest_data.head()', '# View Train bottom data\\ntrain_data.tail()', '# View Test bottom data\\ntest_data.tail()', '# Train attributes data types\\ntrain_data.dtypes', '# Test attributes data types\\ntest_data.dtypes', '# Train Summary\\ntrain_data.describe()', '# Test Summary\\ntest_data.describe()', '# Train dimension\\ntrain_data.shape', '# Test dimension\\ntest_data.shape', '# Train attributes name\\ntrain_data.columns', '# Test attributes name\\ntest_data.columns', '### Train and Test data-sets : Drop insignifican... unique values in Train data\\ntrain_data.nunique()', '# Finding unique values in Test data\\ntest_data.nunique()', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {6:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 7:    PassengerId  Pclass                          ...      1      1  3101298  12.2875   NaN        S  , 8:      PassengerId  Survived  Pclass              ...     0      0      370376   7.75   NaN        Q  , 9:      PassengerId  Pclass                        ... 1                2668   22.3583   NaN        C  , 10: PassengerId      int64\nSurvived         int64\nPc...      object\nEmbarked        object\ndtype: object, 11: PassengerId      int64\nPclass           int64\nNa...      object\nEmbarked        object\ndtype: object, 12:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 13:        PassengerId      Pclass         Age      ...0   76.000000    8.000000    9.000000  512.329200, 14: (891, 12), 15: (418, 11), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# Import supported libraries\\nimport numpy as np\\n...from sklearn.metrics import classification_report', '# Read Train and Test data-sets\\ntrain_data = pd....(\"train.csv\")\\ntest_data = pd.read_csv(\"test.csv\")', 'titanic_train = train_data.copy()\\ntitanic_test = test_data.copy()', '# Gather info from the Train data-set\\ntrain_data.info()', '# Gather info from the Train data-set\\ntest_data.info()', '# View top Train data\\ntrain_data.head()', '# View top Test data\\ntest_data.head()', '# View Train bottom data\\ntrain_data.tail()', '# View Test bottom data\\ntest_data.tail()', '# Train attributes data types\\ntrain_data.dtypes', '# Test attributes data types\\ntest_data.dtypes', '# Train Summary\\ntrain_data.describe()', '# Test Summary\\ntest_data.describe()', '# Train dimension\\ntrain_data.shape', '# Test dimension\\ntest_data.shape', '# Train attributes name\\ntrain_data.columns', '# Test attributes name\\ntest_data.columns', '### Train and Test data-sets : Drop insignifican... unique values in Train data\\ntrain_data.nunique()', '# Finding unique values in Test data\\ntest_data.nunique()', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {6:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 7:    PassengerId  Pclass                          ...      1      1  3101298  12.2875   NaN        S  , 8:      PassengerId  Survived  Pclass              ...     0      0      370376   7.75   NaN        Q  , 9:      PassengerId  Pclass                        ... 1                2668   22.3583   NaN        C  , 10: PassengerId      int64\nSurvived         int64\nPc...      object\nEmbarked        object\ndtype: object, 11: PassengerId      int64\nPclass           int64\nNa...      object\nEmbarked        object\ndtype: object, 12:        PassengerId    Survived      Pclass      ...000   31.000000  \nmax      6.000000  512.329200  , 13:        PassengerId      Pclass         Age      ...0   76.000000    8.000000    9.000000  512.329200, 14: (891, 12), 15: (418, 11), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Studies\\INSOFE\\Self Practice\\titanic data-set\\<ipython-input-108-890652c98351> in <module>()\n----> 1 rs_gbc.fit(x_train, y_train.iloc[:,0])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=10, error_score='raise',\n ...turn_train_score='warn', scoring=None, verbose=2), X=           Age      Fare  Embarked_C  Embarked_Q...   0        0        0  \n\n[623 rows x 24 columns], y=787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], groups=None, **fit_params={'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...   0        0        0  \n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>\n        X =            Age      Fare  Embarked_C  Embarked_Q...   0        0        0  \n\n[623 rows x 24 columns]\n        y = 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nXGBoostError                                       Fri Nov 30 15:38:33 2018\nPID: 1432                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}), {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1),            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], 787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], {'score': <function _passthrough_scorer>}, array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), 2, {'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns], y=787    0\n99     0\n279    1\n315    1\n852    0\n675...23, dtype: category\nCategories (2, int64): [0, 1], scorer={'score': <function _passthrough_scorer>}, train=array([ 62,  64,  65,  66,  67,  68,  69,  70,  ..., 615, 616, 617, 618, 619, 620, 621,\n       622]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63]), verbose=2, parameters={'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 10, 'n_estimators': 200, 'reg_lambda': 5.0}, fit_params={'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...t=1, seed=None, silent=True,\n       subsample=1)>\n        X_train =            Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns]\n        y_train = 660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1]\n        fit_params = {'early_stopping_rounds': 50, 'eval_metric': 'mlogloss', 'eval_set': [(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])]}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None, silent=True,\n       subsample=1), X=           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[560 rows x 24 columns], y=660    1\n74     1\n82     1\n267    1\n591    1\n463...60, dtype: category\nCategories (2, int64): [0, 1], sample_weight=None, eval_set=[(           Age      Fare  Embarked_C  Embarked_Q...     0        0        0\n\n[623 rows x 24 columns],     Survived\n787        0\n99         0\n279      ...548        0\n527        0\n\n[623 rows x 1 columns])], eval_metric='mlogloss', early_stopping_rounds=50, verbose=True, xgb_model=None, sample_weight_eval_set=[None], callbacks=None)\n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n    698                               evals_result=evals_result, obj=obj, feval=feval,\n    699                               verbose_eval=verbose, xgb_model=None,\n--> 700                               callbacks=callbacks)\n        callbacks = None\n    701 \n    702         self.objective = xgb_options[\"objective\"]\n    703         if evals_result:\n    704             for val in evals_result.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in train(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, maximize=False, early_stopping_rounds=50, evals_result={}, verbose_eval=True, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>], learning_rates=None)\n    211 \n    212     return _train_internal(params, dtrain,\n    213                            num_boost_round=num_boost_round,\n    214                            evals=evals,\n    215                            obj=obj, feval=feval,\n--> 216                            xgb_model=xgb_model, callbacks=callbacks)\n        xgb_model = None\n        callbacks = [<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>]\n    217 \n    218 \n    219 class CVPack(object):\n    220     \"\"\"\"Auxiliary datastruct to hold one fold of CV.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py in _train_internal(params={'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.2, 'loss': 'exponential', 'max_delta_step': 0, 'max_depth': 10, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=200, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function early_stop.<locals>.callback>, <function record_evaluation.<locals>.callback>])\n     79 \n     80         nboost += 1\n     81         evaluation_result_list = []\n     82         # check evaluation result.\n     83         if len(evals) != 0:\n---> 84             bst_eval_set = bst.eval_set(evals, i, feval)\n        bst_eval_set = undefined\n        bst.eval_set = <bound method Booster.eval_set of <xgboost.core.Booster object>>\n        evals = [(<xgboost.core.DMatrix object>, 'validation_0')]\n        i = 0\n        feval = None\n     85             if isinstance(bst_eval_set, STRING_TYPES):\n     86                 msg = bst_eval_set\n     87             else:\n     88                 msg = bst_eval_set.decode()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in eval_set(self=<xgboost.core.Booster object>, evals=[(<xgboost.core.DMatrix object>, 'validation_0')], iteration=0, feval=None)\n   1101         evnames = c_array(ctypes.c_char_p, [c_str(d[1]) for d in evals])\n   1102         msg = ctypes.c_char_p()\n   1103         _check_call(_LIB.XGBoosterEvalOneIter(self.handle, ctypes.c_int(iteration),\n   1104                                               dmats, evnames,\n   1105                                               c_bst_ulong(len(evals)),\n-> 1106                                               ctypes.byref(msg)))\n        msg = c_char_p(None)\n   1107         res = msg.value.decode()\n   1108         if feval is not None:\n   1109             for dmat, evname in evals:\n   1110                 feval_ret = feval(self.predict(dmat), dmat)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _check_call(ret=-1)\n    160     ----------\n    161     ret : int\n    162         return value from API calls\n    163     \"\"\"\n    164     if ret != 0:\n--> 165         raise XGBoostError(_LIB.XGBGetLastError())\n    166 \n    167 \n    168 def ctypes2numpy(cptr, length, dtype):\n    169     \"\"\"Convert a ctypes pointer array to a numpy array.\n\nXGBoostError: b'[15:38:33] C:\\\\Users\\\\Administrator\\\\Desktop\\\\xgboost\\\\src\\\\metric\\\\multiclass_metric.cc:53: Check failed: label_error >= 0 && label_error < static_cast<int>(nclass) MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 1 in label'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "rs_gbc.fit(x_train, y_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-127f8638332b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrs_gbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "rs_gbc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_gbc.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
